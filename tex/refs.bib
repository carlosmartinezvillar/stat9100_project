@article{hopfield1982neural,
  title={Neural networks and physical systems with emergent collective computational abilities},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={79},
  number={8},
  pages={2554--2558},
  year={1982},
  publisher={National Acad Sciences}
}

@article{hopfield1984neurons,
  title={Neurons with graded response have collective computational properties like those of two-state neurons},
  author={Hopfield, John J},
  journal={Proceedings of the national academy of sciences},
  volume={81},
  number={10},
  pages={3088--3092},
  year={1984},
  publisher={National Acad Sciences}
}

@book{hebb2005organization,
  title={The organization of behavior: A neuropsychological theory},
  author={Hebb, Donald Olding},
  year={2005},
  publisher={Psychology Press}
}

@book{haykin,
Author = {Haykin, Simon S.},
ISBN = {9780023527616},
Publisher = {Prentice Hall},
Title = {Neural networks : a comprehensive foundation.},
URL = {http://proxy.mul.missouri.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=cat04885a&AN=merlin.b3399286&site=eds-live&scope=site},
Year = {1994},
}

@article{krotov2016dense,
  title={Dense associative memory for pattern recognition},
  author={Krotov, Dmitry and Hopfield, John J},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC and Mac Kay, David JC and others},
  year={2003},
  publisher={Cambridge university press}
}


@article{deeplearning2015,
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  date = {2015/05/01},
  date-added = {2022-05-14 15:58:27 -0500},
  date-modified = {2022-05-14 15:59:03 -0500},
  doi = {10.1038/nature14539},
  id = {LeCun2015},
  isbn = {1476-4687},
  journal = {Nature},
  number = {7553},
  pages = {436--444},
  title = {Deep learning},
  url = {https://doi.org/10.1038/nature14539},
  volume = {521},
  year = {2015},
  }

@article{lecun1989,
  author    = {Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jackel},
  journal   = {Neural Computation},
  title     = {Backpropagation Applied to Handwritten Zip Code Recognition},
  year      = {1989},
  number    = {4},
  pages     = {541--551},
  volume    = {1},
  doi       = {10.1162/neco.1989.1.4.541},
  file      = {:/Users/cimv/Desktop/QE3/lecun_1989.pdf:PDF},
  publisher = {{MIT} Press - Journals},
  keywords   = {selected}
}

@incollection{hinton2012practical,
  title={A practical guide to training restricted Boltzmann machines},
  author={Hinton, Geoffrey E},
  booktitle={Neural networks: Tricks of the trade},
  pages={599--619},
  year={2012},
  publisher={Springer}
}